{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNIyGI40dYlhi19ecFHoo0v"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **Chargement des données**"],"metadata":{"id":"ZXNPUqYOd-Q2"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"FoEytwH8Klrr"},"outputs":[],"source":["# Charge les packages\n","import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPool2D\n","from tensorflow.keras.callbacks import EarlyStopping"]},{"cell_type":"code","source":["# Charge le FASHION-MNIST dataset\n","(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n","\n","X_train = X_train.astype('float32') / 255\n","X_test = X_test.astype('float32') / 255\n","\n","X_train = np.expand_dims(X_train, axis= -1)\n","X_test = np.expand_dims(X_test, axis= -1)\n","\n","y_train_OneHot = to_categorical(y_train)\n","y_test_OneHot = to_categorical(y_test)"],"metadata":{"id":"GCSD5IZlLauj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Affiche quelques informations sur le dataset\n","n_class = len(np.unique(y_train))\n","print(f\"Il y a {n_class} types de vêtements différent dans le dataset\")\n","print(f\"Il y a {X_train.shape[0]} exemples dans le dataset d'entrainement\")\n","print(f\"Format des images : {X_train.shape[1:]} pixels\")"],"metadata":{"id":"CBcoYiFU35-w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ids_to_label = {\n","    0 : 't-shirt / haut',\n","    1 : 'pantalon',\n","    2 : 'pull',\n","    3 : 'robe',\n","    4 : 'manteau',\n","    5 : 'sandale',\n","    6 : 'chemise',\n","    7 : 'sneaker',\n","    8 : 'sac',\n","    9 : 'chaussures'\n","}"],"metadata":{"id":"Kbro8X2M7-dy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Définition de fonctions pour visualiser et monitorer**"],"metadata":{"id":"-6DFWZ2veX53"}},{"cell_type":"code","source":["# Fonction pour afficher une image\n","def display_image(img_number: int, dataset= 'train') :\n","  if dataset == \"train\" :\n","    img = X_train[img_number, :, :]\n","    label = ids_to_label[y_train[img_number]]\n","\n","  elif dataset == 'test' :\n","    img = X_test[img_number, :, :]\n","    label = ids_to_label[y_test[img_number]]\n","\n","  plt.figure(figsize= (5,5))\n","  plt.imshow(img, cmap= 'gray');\n","  plt.title(str(label))\n","  plt.axis('off')\n","  plt.show();\n","\n","  return None"],"metadata":{"id":"npBNbEMNMOMV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["display_image(1)"],"metadata":{"id":"jzvbBMMB5_7B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Fonction pour monitorer l'entrainement du modèle\n","def display_training(history) :\n","  train_acc = history.history['accuracy']\n","  val_acc = history.history['val_accuracy']\n","  x_axis= np.arange(len(train_acc))\n","\n","  plt.figure(figsize= (8,6))\n","  plt.plot(x_axis, train_acc, c= 'b', label= 'Training accuracy')\n","  plt.plot(x_axis, val_acc, c= 'g', label= 'Validation accuracy')\n","  plt.title('Training and validation accuracy')\n","  plt.xlabel('Epochs')\n","  plt.ylabel('Accuracy en %')\n","  plt.legend()\n","  plt.show();"],"metadata":{"id":"dgqAexGEbbCu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Fonction pour visualiser les prédictions du modèle\n","def display_predictions(correct_or_error, seed= 42) :\n","\n","  np.random.seed(seed)\n","  y_pred = model.predict(X_test)\n","  y_pred = np.argmax(y_pred, axis= 1)\n","\n","  if correct_or_error == 'correct' :\n","    mask = (y_pred == y_test)\n","  elif correct_or_error == 'error' :\n","    mask = (y_pred != y_test)\n","\n","  y_pred_restricted = y_pred[mask]\n","  y_test_restricted = y_test[mask]\n","  X_test_restricted = X_test[mask, :, :]\n","\n","  idx = np.random.choice(a= len(y_pred_restricted), size= 8, replace= False)\n","  pred_labels = [ids_to_label[y_pred_restricted[i]] for i in idx]\n","  test_labels = [ids_to_label[y_test_restricted[i]] for i in idx]\n","\n","  plt.figure(figsize= (12, 6))\n","  for i in range(2) :\n","    for j in range(4) :\n","      plt.subplot(2, 4, 4*i+j+1)\n","      plt.imshow(X_test_restricted[idx[4*i+j], :, :], cmap= 'gray')\n","      plt.title(f'Prédiction : {pred_labels[4*i+j]}\\nVrai : {test_labels[4*i+j]}')\n","      plt.axis('off')\n","\n","  return None"],"metadata":{"id":"2_UbmwWdxpEb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Création et entrainement du modèle**"],"metadata":{"id":"Qcht_VPResLg"}},{"cell_type":"code","source":["# Définit l'architecture du Réseau de Neurones\n","class NeuralNetwork(tf.keras.Model) :\n","  def __init__(self, n_hidden= 1, hidden_size = [64], n_class= n_class) :\n","    super().__init__()\n","\n","    self.n_class = n_class\n","    self.n_hidden = n_hidden\n","\n","    assert n_hidden == len(hidden_size), \\\n","    f'ATTENTION, \"n_hidden\" indique {n_hidden} couches dans le modèle mais seules {len(hidden_size)} sont définies dans \"hidden_size\"'\n","\n","    self.flatten = Flatten(input_shape= (28, 28))\n","    self.input_dense = Dense(units= 16, activation= 'relu')\n","\n","    self.hidden_layer_list = list()\n","    for i in range(n_hidden) :\n","      layer = Dense(units= hidden_size[i], activation= 'relu')\n","      self.hidden_layer_list.append(layer)\n","\n","    self.output_dense = Dense(units= n_class, activation= 'softmax')\n","\n","  def call(self, inputs) :\n","    x = self.flatten(inputs)\n","    x = self.input_dense(x)\n","    for i in range(self.n_hidden) :\n","      x = self.hidden_layer_list[i](x)\n","\n","    output = self.output_dense(x)\n","\n","    return output"],"metadata":{"id":"ULAbXagF6XVj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Paramètres utilisateurs\n","n_hidden= 1\n","hidden_size= [32]\n","n_epochs = 20\n","batch_size = 32\n","\n","# Créer et initialise le modèle\n","model = NeuralNetwork(n_hidden= n_hidden,\n","                      hidden_size= hidden_size,\n","                      n_class= n_class)\n","\n","model.compile(optimizer= 'adam',\n","              loss= 'categorical_crossentropy',\n","              metrics= ['accuracy'])"],"metadata":{"id":"jHpKZHuJM1q0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["callbacks = [\n","    EarlyStopping(monitor= 'val_accuracy',\n","                  patience= 3,\n","                  mode= 'max',\n","                  min_delta= 5e-4,\n","                  restore_best_weights= True)\n","    ]\n","\n","# Entraine le modèle\n","history = model.fit(\n","    x= X_train,\n","    y= y_train_OneHot,\n","    batch_size= batch_size,\n","    epochs= n_epochs,\n","    validation_data= (X_test, y_test_OneHot),\n","    callbacks= callbacks\n","    )\n","\n","print(f'\\nLe modèle a {model.evaluate(X_test, y_test_OneHot)[1] *100:.0f}% de bonnes réponses sur le dataset de test')"],"metadata":{"id":"DufxjfI8QWcl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualisation de l'entrainement du modèle\n","display_training(history)"],"metadata":{"id":"-LUCipRHdasC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualisation des exemples correctement classifiés par le modèle\n","display_predictions(correct_or_error= 'correct', seed= 123)"],"metadata":{"id":"W3IvQlf0uF66"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualisation des exemples mal classifiés par le modèle\n","display_predictions(correct_or_error= 'error', seed= 123)"],"metadata":{"id":"lHi6tPeXddZg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Test avec un Convolution Network**"],"metadata":{"id":"iaODkn_nkay0"}},{"cell_type":"code","source":["# Définit l'architecture du Réseau de Neurones\n","class ConvNetwork(tf.keras.Model) :\n","  def __init__(self, n_class= n_class) :\n","    super().__init__()\n","\n","    self.conv1 = Conv2D(filters= 16, kernel_size= (3,3), padding= 'same', activation= 'relu')\n","    self.pool1 = MaxPool2D(pool_size= (2,2), strides= (2,2))\n","    self.conv2 = Conv2D(filters= 32, kernel_size= (3,3), padding= 'same', activation= 'relu')\n","    self.pool2 = MaxPool2D(pool_size= (2,2), strides= (2,2))\n","\n","    self.flatten = Flatten()\n","    self.dense1 = Dense(units= 32)\n","    self.output_dense = Dense(units= n_class, activation= 'softmax')\n","\n","  def call(self, inputs) :\n","    x = self.conv1(inputs)\n","    x = self.pool1(x)\n","    x = self.conv2(x)\n","    x = self.pool2(x)\n","    x = self.flatten(x)\n","    x = self.dense1(x)\n","    output = self.output_dense(x)\n","\n","    return output"],"metadata":{"id":"8uwgWsOGU8lO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = ConvNetwork(n_class= n_class)\n","\n","model.compile(optimizer= 'adam',\n","              loss= 'categorical_crossentropy',\n","              metrics= ['accuracy'])\n","\n","# Entraine le modèle\n","history = model.fit(\n","    x= X_train,\n","    y= y_train_OneHot,\n","    batch_size= batch_size,\n","    epochs= n_epochs,\n","    validation_data= (X_test, y_test_OneHot),\n","    callbacks= callbacks\n","    )\n","\n","print(f'\\nLe modèle a {model.evaluate(X_test, y_test_OneHot)[1] *100:.0f}% de bonnes réponses sur le dataset de test')"],"metadata":{"id":"kBVIi4kGknT8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualisation de l'entrainement du modèle\n","display_training(history)"],"metadata":{"id":"Abu7EXEDk_PF"},"execution_count":null,"outputs":[]}]}